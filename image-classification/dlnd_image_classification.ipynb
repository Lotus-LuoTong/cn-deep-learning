{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [24:27, 116kB/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 7:\n",
      "Image - Min Value: 9 Max Value: 248\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 7 Name: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a257be7b8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 7\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = np.array(x)\n",
    "    res = (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "    return res\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    lb = LabelBinarizer().fit(np.arange(10))\n",
    "    res = lb.transform(x)\n",
    "    return res\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='x', \\\n",
    "                          shape=[None, image_shape[0], image_shape[1], image_shape[2]])\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='y', shape=[None, n_classes])\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs]))\n",
    "    bias = tf.Variable(tf.truncated_normal([conv_num_outputs]))\n",
    "    conv1 = tf.nn.conv2d(x_tensor, weight, strides=[1,conv_strides[0], conv_strides[1],1], padding='VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1, bias)\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    pool1 = tf.nn.max_pool(conv1, \\\n",
    "                           [1,pool_ksize[0], pool_ksize[1],1], \\\n",
    "                           [1,pool_strides[0], pool_strides[1],1], \\\n",
    "                            padding='VALID')\n",
    "    return pool1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function \n",
    "    # print(x_tensor)\n",
    "    # print(x_tensor.shape)\n",
    "    # print(tf.shape(x_tensor))\n",
    "    res = tf.reshape(x_tensor, shape=[-1,x_tensor.shape[1]*x_tensor.shape[2]*x_tensor.shape[3]])\n",
    "    return res\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, conv_num_outputs=10, conv_ksize=(5,5), conv_strides=(2,2), \\\n",
    "                          pool_ksize=(5,5), pool_strides=(2,2))\n",
    "    #conv = conv2d_maxpool(conv, conv_num_outputs=10, conv_ksize=(2,2), conv_strides=(1,1), \\\n",
    "    #                      pool_ksize=(2,2), pool_strides=(1,1))\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    flcn = fully_conn(flat, num_outputs=50)\n",
    "    #flcn = fully_conn(flcn, num_outputs=20)\n",
    "    flcn = fully_conn(flcn, num_outputs=10)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    logits = output(flcn, num_outputs=10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.})\n",
    "    acc = session.run(accuracy, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.})\n",
    "    print('Loss:{}\\tValidation Accuracy:{}'.format(loss, acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:2.3091378211975098\tValidation Accuracy:0.12999999523162842\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:2.228564739227295\tValidation Accuracy:0.16899999976158142\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:2.2145557403564453\tValidation Accuracy:0.16279999911785126\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:2.1987037658691406\tValidation Accuracy:0.21240000426769257\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:2.1841750144958496\tValidation Accuracy:0.22120000422000885\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:2.1724815368652344\tValidation Accuracy:0.24779999256134033\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:2.1671085357666016\tValidation Accuracy:0.25619998574256897\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:2.164794683456421\tValidation Accuracy:0.26499998569488525\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:2.1569254398345947\tValidation Accuracy:0.28279998898506165\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:2.1441848278045654\tValidation Accuracy:0.29120001196861267\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:2.088221788406372\tValidation Accuracy:0.3043999969959259\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:2.0772767066955566\tValidation Accuracy:0.3041999936103821\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:2.043457508087158\tValidation Accuracy:0.3041999936103821\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:2.0310897827148438\tValidation Accuracy:0.3068000078201294\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:2.02236270904541\tValidation Accuracy:0.3125999867916107\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:1.9867147207260132\tValidation Accuracy:0.31940001249313354\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:1.9686663150787354\tValidation Accuracy:0.32359999418258667\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:1.9434125423431396\tValidation Accuracy:0.3310000002384186\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:1.9368938207626343\tValidation Accuracy:0.32580000162124634\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:1.918069839477539\tValidation Accuracy:0.3285999894142151\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:1.9174617528915405\tValidation Accuracy:0.3458000123500824\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:1.9145885705947876\tValidation Accuracy:0.35440000891685486\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:1.8623253107070923\tValidation Accuracy:0.36480000615119934\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:1.8490543365478516\tValidation Accuracy:0.37279999256134033\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:1.8044344186782837\tValidation Accuracy:0.375\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:1.7034833431243896\tValidation Accuracy:0.40139999985694885\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:1.6804431676864624\tValidation Accuracy:0.4092000126838684\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:1.6507892608642578\tValidation Accuracy:0.4212000072002411\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:1.6324703693389893\tValidation Accuracy:0.4212000072002411\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:1.6385653018951416\tValidation Accuracy:0.42239999771118164\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:1.6230039596557617\tValidation Accuracy:0.430400013923645\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:1.6040780544281006\tValidation Accuracy:0.43779999017715454\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:1.5878419876098633\tValidation Accuracy:0.4357999861240387\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:1.5621676445007324\tValidation Accuracy:0.4408000111579895\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:1.5548484325408936\tValidation Accuracy:0.44040000438690186\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:1.5472772121429443\tValidation Accuracy:0.4442000091075897\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:1.5162649154663086\tValidation Accuracy:0.44620001316070557\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:1.5027060508728027\tValidation Accuracy:0.44839999079704285\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:1.4880609512329102\tValidation Accuracy:0.4449999928474426\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:1.4877536296844482\tValidation Accuracy:0.44699999690055847\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:1.4799093008041382\tValidation Accuracy:0.4505999982357025\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:1.472426414489746\tValidation Accuracy:0.45080000162124634\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:1.4728825092315674\tValidation Accuracy:0.45339998602867126\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:1.4730026721954346\tValidation Accuracy:0.4490000009536743\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:1.47320556640625\tValidation Accuracy:0.44999998807907104\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:1.4473350048065186\tValidation Accuracy:0.45239999890327454\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:1.4537336826324463\tValidation Accuracy:0.4560000002384186\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:1.4534295797348022\tValidation Accuracy:0.45579999685287476\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:1.428602933883667\tValidation Accuracy:0.45899999141693115\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:1.4224233627319336\tValidation Accuracy:0.4580000042915344\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:1.4150168895721436\tValidation Accuracy:0.4596000015735626\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:1.4016939401626587\tValidation Accuracy:0.45879998803138733\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:1.3937838077545166\tValidation Accuracy:0.4575999975204468\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:1.392840027809143\tValidation Accuracy:0.4593999981880188\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:1.3816906213760376\tValidation Accuracy:0.46239998936653137\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:1.384856104850769\tValidation Accuracy:0.462799996137619\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:1.3677804470062256\tValidation Accuracy:0.46399998664855957\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:1.3621366024017334\tValidation Accuracy:0.46560001373291016\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:1.355672001838684\tValidation Accuracy:0.4666000008583069\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:1.3596842288970947\tValidation Accuracy:0.47200000286102295\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:1.3475911617279053\tValidation Accuracy:0.4699999988079071\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:1.3425111770629883\tValidation Accuracy:0.47040000557899475\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:1.3327802419662476\tValidation Accuracy:0.46959999203681946\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:1.3289639949798584\tValidation Accuracy:0.4681999981403351\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:1.3100913763046265\tValidation Accuracy:0.46860000491142273\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:1.3050460815429688\tValidation Accuracy:0.4708000123500824\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:1.3014347553253174\tValidation Accuracy:0.46959999203681946\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:1.2955806255340576\tValidation Accuracy:0.46540001034736633\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:1.2901743650436401\tValidation Accuracy:0.4659999907016754\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:1.277980089187622\tValidation Accuracy:0.4668000042438507\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:1.2703489065170288\tValidation Accuracy:0.46540001034736633\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:1.2631876468658447\tValidation Accuracy:0.46560001373291016\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:1.2480523586273193\tValidation Accuracy:0.46480000019073486\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:1.246490478515625\tValidation Accuracy:0.4650000035762787\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:1.240028977394104\tValidation Accuracy:0.4659999907016754\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:1.2331202030181885\tValidation Accuracy:0.46799999475479126\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:1.2316826581954956\tValidation Accuracy:0.46619999408721924\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:1.2259355783462524\tValidation Accuracy:0.46560001373291016\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:1.2182782888412476\tValidation Accuracy:0.46639999747276306\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:1.2133623361587524\tValidation Accuracy:0.46560001373291016\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:1.209631323814392\tValidation Accuracy:0.4657999873161316\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:1.211679220199585\tValidation Accuracy:0.46619999408721924\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:1.2043633460998535\tValidation Accuracy:0.46639999747276306\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:1.1935688257217407\tValidation Accuracy:0.46700000762939453\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:1.1883149147033691\tValidation Accuracy:0.46639999747276306\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:1.1795552968978882\tValidation Accuracy:0.46619999408721924\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:1.1600514650344849\tValidation Accuracy:0.46639999747276306\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:1.1570533514022827\tValidation Accuracy:0.4652000069618225\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:1.1514123678207397\tValidation Accuracy:0.4652000069618225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, CIFAR-10 Batch 1:  Loss:1.1398353576660156\tValidation Accuracy:0.46639999747276306\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:1.1388473510742188\tValidation Accuracy:0.4650000035762787\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:1.135679006576538\tValidation Accuracy:0.46799999475479126\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:1.1356515884399414\tValidation Accuracy:0.4699999988079071\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:1.1253774166107178\tValidation Accuracy:0.46939998865127563\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:1.1096075773239136\tValidation Accuracy:0.4691999852657318\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:1.1271467208862305\tValidation Accuracy:0.4641999900341034\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:1.113974928855896\tValidation Accuracy:0.4652000069618225\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:1.1110520362854004\tValidation Accuracy:0.46239998936653137\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:1.099547266960144\tValidation Accuracy:0.4652000069618225\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:1.097801923751831\tValidation Accuracy:0.4641999900341034\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:1.0926021337509155\tValidation Accuracy:0.459199994802475\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:1.0742747783660889\tValidation Accuracy:0.4586000144481659\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:1.0812748670578003\tValidation Accuracy:0.45820000767707825\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:1.0723870992660522\tValidation Accuracy:0.45719999074935913\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:1.0747716426849365\tValidation Accuracy:0.45660001039505005\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:1.0673249959945679\tValidation Accuracy:0.4596000015735626\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:1.0519688129425049\tValidation Accuracy:0.46059998869895935\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:1.0474838018417358\tValidation Accuracy:0.4602000117301941\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:1.0451040267944336\tValidation Accuracy:0.45899999141693115\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:1.0331780910491943\tValidation Accuracy:0.45840001106262207\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:1.0213955640792847\tValidation Accuracy:0.45879998803138733\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:1.0226421356201172\tValidation Accuracy:0.45899999141693115\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:1.0156240463256836\tValidation Accuracy:0.45820000767707825\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:1.016303300857544\tValidation Accuracy:0.46160000562667847\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:1.0008819103240967\tValidation Accuracy:0.4620000123977661\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:1.0047086477279663\tValidation Accuracy:0.46399998664855957\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:1.0007004737854004\tValidation Accuracy:0.46459999680519104\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:1.0034596920013428\tValidation Accuracy:0.46380001306533813\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:1.0008108615875244\tValidation Accuracy:0.46299999952316284\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:0.9913011789321899\tValidation Accuracy:0.4641999900341034\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:0.9990800619125366\tValidation Accuracy:0.4652000069618225\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:0.9920109510421753\tValidation Accuracy:0.462799996137619\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:0.9811664819717407\tValidation Accuracy:0.4650000035762787\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:0.9850507974624634\tValidation Accuracy:0.46860000491142273\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:0.9723118543624878\tValidation Accuracy:0.4681999981403351\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:0.9624086618423462\tValidation Accuracy:0.4702000021934509\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:0.9709860682487488\tValidation Accuracy:0.46779999136924744\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:0.9614828824996948\tValidation Accuracy:0.46799999475479126\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:0.9674894213676453\tValidation Accuracy:0.4666000008583069\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:0.9590867757797241\tValidation Accuracy:0.46459999680519104\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:0.9652330279350281\tValidation Accuracy:0.462799996137619\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:0.9648905992507935\tValidation Accuracy:0.46140000224113464\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:0.9709891080856323\tValidation Accuracy:0.4659999907016754\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:0.9589803814888\tValidation Accuracy:0.46619999408721924\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:0.9589786529541016\tValidation Accuracy:0.46320000290870667\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:0.9477120637893677\tValidation Accuracy:0.4636000096797943\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:0.9620760679244995\tValidation Accuracy:0.46219998598098755\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:0.9462257623672485\tValidation Accuracy:0.460999995470047\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:0.9389572143554688\tValidation Accuracy:0.459199994802475\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:0.9427372217178345\tValidation Accuracy:0.4596000015735626\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:0.9358186721801758\tValidation Accuracy:0.45879998803138733\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:0.9263965487480164\tValidation Accuracy:0.4596000015735626\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:0.9251850247383118\tValidation Accuracy:0.45899999141693115\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:0.9127200841903687\tValidation Accuracy:0.4586000144481659\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:0.924460768699646\tValidation Accuracy:0.459199994802475\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:0.9293032884597778\tValidation Accuracy:0.4586000144481659\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:0.9278007745742798\tValidation Accuracy:0.4620000123977661\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:0.9301397204399109\tValidation Accuracy:0.462799996137619\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:0.9372550845146179\tValidation Accuracy:0.46140000224113464\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:0.9453072547912598\tValidation Accuracy:0.4611999988555908\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:0.9241860508918762\tValidation Accuracy:0.460999995470047\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:0.9366685748100281\tValidation Accuracy:0.4611999988555908\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:0.9471160173416138\tValidation Accuracy:0.45899999141693115\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:0.9633394479751587\tValidation Accuracy:0.4593999981880188\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:0.9480632543563843\tValidation Accuracy:0.45980000495910645\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:0.958229660987854\tValidation Accuracy:0.45879998803138733\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:0.9560433626174927\tValidation Accuracy:0.4578000009059906\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:0.9609807729721069\tValidation Accuracy:0.4578000009059906\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:0.9711359143257141\tValidation Accuracy:0.45579999685287476\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:0.9770106077194214\tValidation Accuracy:0.45660001039505005\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:0.9705648422241211\tValidation Accuracy:0.4586000144481659\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:0.9612367749214172\tValidation Accuracy:0.4569999873638153\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:0.9501779675483704\tValidation Accuracy:0.4560000002384186\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:0.9454711675643921\tValidation Accuracy:0.4562000036239624\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:0.9318162202835083\tValidation Accuracy:0.4580000042915344\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:0.9383677244186401\tValidation Accuracy:0.4596000015735626\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:0.9468985795974731\tValidation Accuracy:0.4607999920845032\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:0.9370786547660828\tValidation Accuracy:0.4659999907016754\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:0.9429486989974976\tValidation Accuracy:0.46480000019073486\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:0.9437153935432434\tValidation Accuracy:0.46619999408721924\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:0.9178417325019836\tValidation Accuracy:0.4643999934196472\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:0.9117978811264038\tValidation Accuracy:0.46480000019073486\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:0.9033797979354858\tValidation Accuracy:0.4666000008583069\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:0.8967583775520325\tValidation Accuracy:0.4659999907016754\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:0.8947135806083679\tValidation Accuracy:0.4674000144004822\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:0.8877167701721191\tValidation Accuracy:0.4659999907016754\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:0.8693022727966309\tValidation Accuracy:0.4650000035762787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178, CIFAR-10 Batch 1:  Loss:0.867965042591095\tValidation Accuracy:0.4643999934196472\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:0.8621317148208618\tValidation Accuracy:0.46219998598098755\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:0.858960747718811\tValidation Accuracy:0.460999995470047\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:0.855390191078186\tValidation Accuracy:0.4620000123977661\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:0.8516813516616821\tValidation Accuracy:0.4636000096797943\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:0.853015124797821\tValidation Accuracy:0.4618000090122223\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:0.8514442443847656\tValidation Accuracy:0.46140000224113464\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:0.8510467410087585\tValidation Accuracy:0.4586000144481659\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:0.8354185223579407\tValidation Accuracy:0.462799996137619\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:0.8307434320449829\tValidation Accuracy:0.462799996137619\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:0.8398928642272949\tValidation Accuracy:0.462799996137619\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:0.8390792012214661\tValidation Accuracy:0.4607999920845032\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:0.8334986567497253\tValidation Accuracy:0.46299999952316284\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:0.8160880208015442\tValidation Accuracy:0.46160000562667847\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:0.8213451504707336\tValidation Accuracy:0.46219998598098755\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:0.8249666094779968\tValidation Accuracy:0.46239998936653137\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:0.8379758596420288\tValidation Accuracy:0.45980000495910645\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:0.8256381750106812\tValidation Accuracy:0.4607999920845032\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:0.8200566172599792\tValidation Accuracy:0.4602000117301941\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:0.8126394152641296\tValidation Accuracy:0.45899999141693115\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:0.8134790658950806\tValidation Accuracy:0.4575999975204468\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:0.8218504190444946\tValidation Accuracy:0.4580000042915344\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:0.81598299741745\tValidation Accuracy:0.4580000042915344\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
